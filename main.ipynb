{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - 190349K\n",
    "\n",
    "## Info\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- Set `DATA_C1` and `DATA_C2` to paths containing datasets\n",
    "- Set `MODEL_DIR` to directory where models should be saved\n",
    "\n",
    "### Saving and loading models\n",
    "\n",
    "-   Models that are trained are also saved to `models/` in the `joblib` format\n",
    "-   Set `RETRAIN` to `False` to load saved models from `models/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and inspecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from enum import Enum\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Label(Enum):\n",
    "    \"\"\"Labels of datasets\"\"\"\n",
    "\n",
    "    C = \"common\"\n",
    "    L1 = \"label_1\"\n",
    "    L2 = \"label_2\"\n",
    "    L3 = \"label_3\"\n",
    "    L4 = \"label_4\"\n",
    "\n",
    "\n",
    "class L(Enum):\n",
    "    \"\"\"Layers of the dataset\"\"\"\n",
    "\n",
    "    C1 = \"layer-7\"\n",
    "    C2 = \"layer-12\"\n",
    "\n",
    "\n",
    "class K(Enum):\n",
    "    \"\"\"Kinds of datasets\"\"\"\n",
    "\n",
    "    TRAIN = \"train\"\n",
    "    VALID = \"valid\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "\n",
    "ID = \"ID\"\n",
    "LABELS = [l.value for l in Label if l != Label.C]\n",
    "AGE_LABEL = Label.L2\n",
    "FEATURE_COUNT = 768\n",
    "FEATURES = [f\"feature_{i}\" for i in range(1, FEATURE_COUNT + 1)]\n",
    "RETRAIN = True  # Retrain the model or load the saved one\n",
    "VERBOSE = True\n",
    "RNG_SEED = 42\n",
    "RNG = np.random.RandomState(RNG_SEED)\n",
    "\n",
    "DATA_C1 = \"data/layer-7\"\n",
    "DATA_C2 = \"data/layer-12\"\n",
    "MODEL_DIR = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(*args, **kwargs):\n",
    "    if VERBOSE:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data: Dict[L, Dict[K, pd.DataFrame]] = {L.C1: {}, L.C2: {}}\n",
    "data[L.C1][K.TRAIN] = pd.read_csv(f\"{DATA_C1}/train.csv\")\n",
    "data[L.C1][K.VALID] = pd.read_csv(f\"{DATA_C1}/valid.csv\")\n",
    "data[L.C1][K.TEST] = pd.read_csv(f\"{DATA_C1}/test.csv\")\n",
    "data[L.C1][K.TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C2][K.TRAIN] = pd.read_csv(f\"{DATA_C2}/train.csv\")\n",
    "data[L.C2][K.VALID] = pd.read_csv(f\"{DATA_C2}/valid.csv\")\n",
    "data[L.C2][K.TEST] = pd.read_csv(f\"{DATA_C2}/test.csv\")\n",
    "data[L.C2][K.TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C1][K.TRAIN][LABELS + FEATURES[::32]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C2][K.TRAIN][LABELS + FEATURES[::32]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDfs = Dict[L, Dict[Label, pd.DataFrame]]\n",
    "LSer = Dict[L, Dict[Label, pd.Series]]\n",
    "\n",
    "# To store datasets\n",
    "X_train: LDfs = {L.C1: {}, L.C2: {}}\n",
    "X_valid: LDfs = {L.C1: {}, L.C2: {}}\n",
    "X_test: LDfs = {L.C1: {}, L.C2: {}}\n",
    "y_train: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_valid: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_pred_before: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_pred_after: LSer = {L.C1: {}, L.C2: {}}\n",
    "\n",
    "\n",
    "def filter_missing_age(df: pd.DataFrame):\n",
    "    \"\"\"Filter out rows where age is `NaN`\"\"\"\n",
    "    return df[df[AGE_LABEL.value].notna()]\n",
    "\n",
    "\n",
    "# Separately store datasets\n",
    "for layer in L:\n",
    "    try:\n",
    "        train_df = data[layer][K.TRAIN]\n",
    "        valid_df = data[layer][K.VALID]\n",
    "        test_df = data[layer][K.TEST]\n",
    "    except:\n",
    "        print(layer, \"not found\")\n",
    "\n",
    "    X_train[layer][Label.C] = train_df.drop(LABELS, axis=1)\n",
    "    X_valid[layer][Label.C] = valid_df.drop(LABELS, axis=1)\n",
    "    X_test[layer][Label.C] = test_df.copy()\n",
    "\n",
    "    for target_label in [Label.L1, Label.L2, Label.L3, Label.L4]:\n",
    "        tr_df = filter_missing_age(train_df) if target_label == AGE_LABEL else train_df\n",
    "        vl_df = filter_missing_age(valid_df) if target_label == AGE_LABEL else valid_df\n",
    "        ts_df = test_df  # No need to filter rows with missing age in test dataset\n",
    "\n",
    "        if target_label == AGE_LABEL:\n",
    "            X_train[layer][target_label] = tr_df.drop(LABELS, axis=1)\n",
    "            X_valid[layer][target_label] = vl_df.drop(LABELS, axis=1)\n",
    "            X_test[layer][target_label] = ts_df.copy()\n",
    "        else:\n",
    "            # Only references to common dataframes\n",
    "            X_train[layer][target_label] = X_train[layer][Label.C]\n",
    "            X_valid[layer][target_label] = X_valid[layer][Label.C]\n",
    "            X_test[layer][target_label] = X_test[layer][Label.C]\n",
    "\n",
    "        y_train[layer][target_label] = tr_df[target_label.value]\n",
    "        y_valid[layer][target_label] = vl_df[target_label.value]\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[L.C1][Label.L1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[L.C1][Label.L1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting labels and showing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def filter_nans(y_true: pd.Series, y_pred: pd.Series):\n",
    "    \"\"\"Filter `NaN`s in both `y_true` and `y_pred` based on `NaN`s in `y_true`\"\"\"\n",
    "    return y_true[y_true.isna() == False], y_pred[y_true.isna() == False]\n",
    "\n",
    "\n",
    "def predict(model, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    y_pred: pd.Series = model.predict(X_test)\n",
    "    print(\"Stats:\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(\"F1:\", metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "def save_model(model, name: str):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.mkdir(MODEL_DIR)\n",
    "    joblib.dump(model, f\"{MODEL_DIR}/{name}.joblib\", compress=True)\n",
    "\n",
    "\n",
    "def load_model(name: str):\n",
    "    return joblib.load(f\"{MODEL_DIR}/{name}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def cross_validate(model: BaseEstimator, X: pd.DataFrame, y: pd.Series, cv=5):\n",
    "    log(\"Cross validating...\")\n",
    "    scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, verbose=1)\n",
    "    print(\n",
    "        \"%0.2f accuracy with a standard deviation of %0.2f\"\n",
    "        % (scores.mean(), scores.std())\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "DEFAULT_SVC_PARAMS = {\n",
    "    \"C\": [1, 10, 100, 1000],\n",
    "    \"gamma\": [\"scale\", \"auto\", 1, 0.01, 0.0001],\n",
    "}\n",
    "\n",
    "\n",
    "def tune(\n",
    "    base_estimator: BaseEstimator,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    param_grid: dict = DEFAULT_SVC_PARAMS,\n",
    "    n_jobs=10,\n",
    "    cv=5,\n",
    "):\n",
    "    \"\"\"Tunes the hyperparameters of `base_estimator` using `GridSearchCV`\"\"\"\n",
    "    log(\"Tuning...\")\n",
    "    verbosity = 4 if VERBOSE else 0\n",
    "    sh = GridSearchCV(\n",
    "        base_estimator,\n",
    "        param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbosity,\n",
    "    ).fit(X, y)\n",
    "    print(sh.best_params_)\n",
    "    return sh.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition 1 (layer 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L1\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L1], y_train[L.C1][Label.L1])\n",
    "    save_model(model, \"c1_label_1_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_1_before\")\n",
    "predict(model, X_valid[L.C1][Label.L1], y_valid[L.C1][Label.L1])\n",
    "y_pred_before[L.C1][Label.L1] = model.predict(X_test[L.C1][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L2\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L2], y_train[L.C1][Label.L2])\n",
    "    save_model(model, \"c1_label_2_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_2_before\")\n",
    "predict(model, X_valid[L.C1][Label.L2], y_valid[L.C1][Label.L2])\n",
    "y_pred_before[L.C1][Label.L2] = model.predict(X_test[L.C1][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L3\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L3], y_train[L.C1][Label.L3])\n",
    "    save_model(model, \"c1_label_3_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_3_before\")\n",
    "predict(model, X_valid[L.C1][Label.L3], y_valid[L.C1][Label.L3])\n",
    "y_pred_before[L.C1][Label.L3] = model.predict(X_test[L.C1][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L4\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L4], y_train[L.C1][Label.L4])\n",
    "    save_model(model, \"c1_label_4_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_4_before\")\n",
    "predict(model, X_valid[L.C1][Label.L4], y_valid[L.C1][Label.L4])\n",
    "y_pred_before[L.C1][Label.L4] = model.predict(X_test[L.C1][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition 2 (layer 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L1\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\")\n",
    "    model.fit(X_train[L.C2][Label.L1], y_train[L.C2][Label.L1])\n",
    "    save_model(model, \"c2_label_1_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_1_before\")\n",
    "predict(model, X_valid[L.C2][Label.L1], y_valid[L.C2][Label.L1])\n",
    "y_pred_before[L.C2][Label.L1] = model.predict(X_test[L.C2][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L2\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", C=1000)\n",
    "    model.fit(X_train[L.C2][Label.L2], y_train[L.C2][Label.L2])\n",
    "    save_model(model, \"c2_label_2_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_2_before\")\n",
    "predict(model, X_valid[L.C2][Label.L2], y_valid[L.C2][Label.L2])\n",
    "y_pred_before[L.C2][Label.L2] = model.predict(X_test[L.C2][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L3\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\")\n",
    "    model.fit(X_train[L.C2][Label.L3], y_train[L.C2][Label.L3])\n",
    "    save_model(model, \"c2_label_3_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_3_before\")\n",
    "predict(model, X_valid[L.C2][Label.L3], y_valid[L.C2][Label.L3])\n",
    "y_pred_before[L.C2][Label.L3] = model.predict(X_test[L.C2][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L4\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\")\n",
    "    model.fit(X_train[L.C2][Label.L4], y_train[L.C2][Label.L4])\n",
    "    save_model(model, \"c2_label_4_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_4_before\")\n",
    "predict(model, X_valid[L.C2][Label.L4], y_valid[L.C2][Label.L4])\n",
    "y_pred_before[L.C2][Label.L4] = model.predict(X_test[L.C2][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "def get_pca(pca_variance=0.95):\n",
    "    return PCA(n_components=pca_variance, svd_solver=\"full\", random_state=RNG)\n",
    "\n",
    "\n",
    "def get_transformers(pca_count=5, pca_variance=0.95):\n",
    "    return [(f\"pca_{i}\", get_pca(pca_variance)) for i in range(pca_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 1 (layer 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    model = svm.SVC(kernel=\"rbf\", C=100, gamma=0.0001, random_state=RNG, probability=True)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C1][Label.L1], y_train[L.C1][Label.L1])  # 40s\n",
    "    save_model(pipeline, \"c1_label_1_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c1_label_1_after\")\n",
    "predict(pipeline, X_valid[L.C1][Label.L1], y_valid[L.C1][Label.L1])\n",
    "y_pred_after[L.C1][Label.L1] = pipeline.predict(X_test[L.C1][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    model = svm.SVC(kernel=\"rbf\", C=10, gamma=\"auto\", random_state=RNG)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            # (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C1][Label.L2], y_train[L.C1][Label.L2])  # 1m 50s\n",
    "    save_model(pipeline, \"c1_label_2_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c1_label_2_after\")\n",
    "predict(pipeline, X_valid[L.C1][Label.L2], y_valid[L.C1][Label.L2])\n",
    "y_pred_after[L.C1][Label.L2] = pipeline.predict(X_test[L.C1][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=100, gamma='scale', random_state=RNG, verbose=True)\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C1][Label.L3], y_train[L.C1][Label.L3])  # 40s\n",
    "    save_model(pipeline, \"c1_label_3_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c1_label_3_after\")\n",
    "predict(pipeline, X_valid[L.C1][Label.L3], y_valid[L.C1][Label.L3])\n",
    "y_pred_after[L.C1][Label.L3] = pipeline.predict(X_test[L.C1][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    # model = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=RNG)  # 5m\n",
    "    model = svm.SVC(kernel=\"rbf\", gamma=\"auto\", random_state=RNG, probability=True)  # 2m\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C1][Label.L4], y_train[L.C1][Label.L4])  # 2m\n",
    "    save_model(pipeline, \"c1_label_4_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c1_label_4_after\")\n",
    "predict(pipeline, X_valid[L.C1][Label.L4], y_valid[L.C1][Label.L4])\n",
    "y_pred_after[L.C1][Label.L4] = pipeline.predict(X_test[L.C1][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 2 (layer 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    model = svm.SVC(kernel=\"rbf\", C=1000, gamma=\"scale\", random_state=RNG, probability=True)  # 89%\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=1000, gamma=0.0001, random_state=RNG)  # 86%\n",
    "    # model = CatBoostClassifier(random_state=RNG_SEED)  # 86%\n",
    "    # model = RandomForestClassifier(n_estimators=200, max_depth=50, n_jobs=-1, random_state=RNG)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C2][Label.L1], y_train[L.C2][Label.L1])  # 40s\n",
    "    save_model(pipeline, \"c2_label_1_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c2_label_1_after\")\n",
    "predict(pipeline, X_valid[L.C2][Label.L1], y_valid[L.C2][Label.L1])\n",
    "y_pred_after[L.C2][Label.L1] = pipeline.predict(X_test[L.C2][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    model = svm.SVC(kernel=\"rbf\", C=100, gamma=\"scale\", random_state=RNG, probability=True)  # 1m\n",
    "    # model = CatBoostClassifier(random_state=RNG_SEED)  # 4m\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C2][Label.L2], y_train[L.C2][Label.L2])  # 1m\n",
    "    save_model(pipeline, \"c2_label_2_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c2_label_2_after\")\n",
    "predict(pipeline, X_valid[L.C2][Label.L2], y_valid[L.C2][Label.L2])\n",
    "y_pred_after[L.C2][Label.L2] = pipeline.predict(X_test[L.C2][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    # model = CatBoostClassifier(iterations=300, loss_function=\"MultiClass\", max_depth=6, random_state=RNG_SEED)\n",
    "    model = svm.SVC(kernel=\"rbf\", gamma=\"scale\", C=1, random_state=RNG, probability=True)  # 20s\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C2][Label.L3], y_train[L.C2][Label.L3])  # 20s\n",
    "    save_model(pipeline, \"c2_label_3_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c2_label_3_after\")\n",
    "predict(pipeline, X_valid[L.C2][Label.L3], y_valid[L.C2][Label.L3])\n",
    "y_pred_after[L.C2][Label.L3] = pipeline.predict(X_test[L.C2][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RETRAIN:\n",
    "    transformers = get_transformers(pca_count=1)\n",
    "    model = svm.SVC(kernel=\"rbf\", C=100, class_weight=\"balanced\", random_state=RNG, probability=True)  # 1m\n",
    "    # model = CatBoostClassifier(random_state=RNG_SEED)\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", RobustScaler()),\n",
    "            *transformers,\n",
    "            (\"clf\", model),\n",
    "        ]\n",
    "    )\n",
    "    log(\"Training...\")\n",
    "    pipeline.fit(X_train[L.C2][Label.L4], y_train[L.C2][Label.L4])  # 1m\n",
    "    save_model(pipeline, \"c2_label_4_after\")\n",
    "else:\n",
    "    pipeline = load_model(\"c2_label_4_after\")\n",
    "predict(pipeline, X_valid[L.C2][Label.L4], y_valid[L.C2][Label.L4])\n",
    "y_pred_after[L.C2][Label.L4] = pipeline.predict(X_test[L.C2][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test[layer-7][label_1]:\", X_test[L.C1][Label.L1].shape)\n",
    "print(\"y_pred[layer-7][label_1]:\", y_pred_after[L.C1][Label.L1].shape)\n",
    "print(\"X_test[layer-12][label_1]:\", X_test[L.C2][Label.L1].shape)\n",
    "print(\"y_pred[layer-12][label_1]:\", y_pred_after[L.C2][Label.L1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame(columns=[ID] + LABELS)\n",
    "result1[ID] = X_test[L.C1][Label.L1][ID]\n",
    "for label in [Label.L1, Label.L2, Label.L3, Label.L4]:\n",
    "    result1[label.value] = y_pred_after[L.C1][label].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame(columns=[ID] + LABELS)\n",
    "result2[ID] = X_test[L.C2][Label.L1][ID]\n",
    "for label in [Label.L1, Label.L2, Label.L3, Label.L4]:\n",
    "    result2[label.value] = y_pred_after[L.C2][label].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv(\"results/layer-7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(\"results/layer-12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XAI\n",
    "\n",
    "- Using Local Interpretable Model-Agnostic Explanations (LIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 1 (layer 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"c1_label_1_after\")  # Use pre-trained model\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train[L.C1][Label.L1].values,\n",
    "    feature_names=FEATURES,\n",
    "    class_names=list(map(str, range(1, 61))),  # Range of speaker IDs\n",
    "    discretize_continuous=True,\n",
    "    random_state=RNG_SEED,\n",
    ")\n",
    "\n",
    "i = np.random.randint(0, X_valid[L.C1][Label.L1].shape[0])\n",
    "exp = explainer.explain_instance(\n",
    "    X_valid[L.C1][Label.L1].values[i],\n",
    "    model.predict_proba,  # Requires model to be trained to predict probabilities\n",
    "    num_features=10,\n",
    "    top_labels=1,  # For multi class\n",
    ")\n",
    "\n",
    "print(\"Instance ID:\", X_valid[L.C1][Label.L1].index[i])\n",
    "exp.save_to_file(f\"results/layer-7-label-1-{i}.html\")\n",
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
