{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - 190349K\n",
    "\n",
    "## Info\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- Set `DATA_C1` and `DATA_C2` to paths containing datasets\n",
    "- Set `MODEL_DIR` to directory where models should be saved\n",
    "\n",
    "### Saving and loading models\n",
    "\n",
    "-   Models that are trained are also saved to `models/` in the `joblib` format\n",
    "-   Set `RETRAIN` to `False` to load saved models from `models/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and inspecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Label(Enum):\n",
    "    \"\"\"Labels of datasets\"\"\"\n",
    "\n",
    "    L1 = \"label_1\"\n",
    "    L2 = \"label_2\"\n",
    "    L3 = \"label_3\"\n",
    "    L4 = \"label_4\"\n",
    "\n",
    "\n",
    "class L(Enum):\n",
    "    \"\"\"Layers of the dataset\"\"\"\n",
    "\n",
    "    C1 = \"layer-7\"\n",
    "    C2 = \"layer-12\"\n",
    "\n",
    "\n",
    "class K(Enum):\n",
    "    \"\"\"Kinds of datasets\"\"\"\n",
    "\n",
    "    TRAIN = \"train\"\n",
    "    VALID = \"valid\"\n",
    "    TEST = \"test\"\n",
    "\n",
    "\n",
    "ID = \"ID\"\n",
    "LABELS = [l.value for l in Label]\n",
    "AGE_LABEL = Label.L2\n",
    "FEATURE_COUNT = 768\n",
    "FEATURES = [f\"feature_{i}\" for i in range(1, FEATURE_COUNT + 1)]\n",
    "RETRAIN = True  # Retrain the model or load the saved one\n",
    "VERBOSE = True\n",
    "RNG_SEED = 42\n",
    "\n",
    "DATA_C1 = \"data/layer-7\"\n",
    "DATA_C2 = \"data/layer-12\"\n",
    "MODEL_DIR = \"models\"\n",
    "\n",
    "RNG = np.random.RandomState(RNG_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(*args, **kwargs):\n",
    "    if VERBOSE:\n",
    "        print(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data: Dict[L, Dict[K, pd.DataFrame]] = {L.C1: {}, L.C2: {}}\n",
    "data[L.C1][K.TRAIN] = pd.read_csv(f\"{DATA_C1}/train.csv\")\n",
    "data[L.C1][K.VALID] = pd.read_csv(f\"{DATA_C1}/valid.csv\")\n",
    "data[L.C1][K.TEST] = pd.read_csv(f\"{DATA_C1}/test.csv\")\n",
    "data[L.C1][K.TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C2][K.TRAIN] = pd.read_csv(f\"{DATA_C2}/train.csv\")\n",
    "data[L.C2][K.VALID] = pd.read_csv(f\"{DATA_C2}/valid.csv\")\n",
    "data[L.C2][K.TEST] = pd.read_csv(f\"{DATA_C2}/test.csv\")\n",
    "data[L.C2][K.TRAIN].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C2][K.TRAIN][LABELS + FEATURES[::32]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[L.C2][K.VALID][LABELS + FEATURES[::32]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "LDfs = Dict[L, Dict[Label, pd.DataFrame]]\n",
    "LSer = Dict[L, Dict[Label, pd.Series]]\n",
    "\n",
    "# To store datasets for each label\n",
    "X_train: LDfs = {L.C1: {}, L.C2: {}}\n",
    "X_valid: LDfs = {L.C1: {}, L.C2: {}}\n",
    "X_test: LDfs = {L.C1: {}, L.C2: {}}\n",
    "y_train: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_valid: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_pred_before: LSer = {L.C1: {}, L.C2: {}}\n",
    "y_pred_after: LSer = {L.C1: {}, L.C2: {}}\n",
    "\n",
    "\n",
    "def filter_missing_age(df: pd.DataFrame):\n",
    "    \"\"\"Filter out rows where age is `NaN`\"\"\"\n",
    "    return df[df[AGE_LABEL.value].notna()]\n",
    "\n",
    "\n",
    "# Filter `NaN` and scale datasets\n",
    "for layer in [L.C1, L.C2]:\n",
    "    try:\n",
    "        train_df = data[layer][K.TRAIN]\n",
    "        valid_df = data[layer][K.VALID]\n",
    "        test_df = data[layer][K.TEST]\n",
    "    except:\n",
    "        print(layer, \"not found\")\n",
    "    for target_label in Label:\n",
    "        tr_df = filter_missing_age(train_df) if target_label == AGE_LABEL else train_df\n",
    "        vl_df = filter_missing_age(valid_df) if target_label == AGE_LABEL else valid_df\n",
    "        ts_df = test_df  # No need to filter rows with missing age in test dataset\n",
    "\n",
    "        scaler = RobustScaler()\n",
    "        scaler.fit(tr_df.drop(LABELS, axis=1))\n",
    "        X_train[layer][target_label] = pd.DataFrame(\n",
    "            scaler.transform(tr_df.drop(LABELS, axis=1)), columns=FEATURES\n",
    "        )\n",
    "        y_train[layer][target_label] = tr_df[target_label.value]\n",
    "        X_valid[layer][target_label] = pd.DataFrame(\n",
    "            scaler.transform(vl_df.drop(LABELS, axis=1)), columns=FEATURES\n",
    "        )\n",
    "        y_valid[layer][target_label] = vl_df[target_label.value]\n",
    "        X_test[layer][target_label] = pd.DataFrame(\n",
    "            scaler.transform(ts_df.drop(ID, axis=1)), columns=FEATURES\n",
    "        )\n",
    "        X_test[layer][target_label][ID] = ts_df[ID]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[L.C1][Label.L1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[L.C1][Label.L1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting labels and showing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def filter_nans(y_true: pd.Series, y_pred: pd.Series):\n",
    "    \"\"\"Filter `NaN`s in both `y_true` and `y_pred` based on `NaN`s in `y_true`\"\"\"\n",
    "    return y_true[y_true.isna() == False], y_pred[y_true.isna() == False]\n",
    "\n",
    "\n",
    "def predict(model, X_test: pd.DataFrame, y_test: pd.Series):\n",
    "    y_pred: pd.Series = model.predict(X_test)\n",
    "    print(\"Stats:\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(\"F1:\", metrics.f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "def save_model(model, name: str):\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.mkdir(MODEL_DIR)\n",
    "    joblib.dump(model, f\"{MODEL_DIR}/{name}.joblib\", compress=True)\n",
    "\n",
    "\n",
    "def load_model(name: str):\n",
    "    return joblib.load(f\"{MODEL_DIR}/{name}.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def cross_validate(model: BaseEstimator, X: pd.DataFrame, y: pd.Series):\n",
    "    log(\"Cross validating...\")\n",
    "    scores = cross_val_score(model, X, y, cv=5, n_jobs=-1)\n",
    "    print(\n",
    "        \"%0.2f accuracy with a standard deviation of %0.2f\"\n",
    "        % (scores.mean(), scores.std())\n",
    "    )\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "\n",
    "def tune(base_estimator, X, y, param_grid: dict = {}, n_jobs=10):\n",
    "    \"\"\"Tunes the hyperparameters of `base_estimator` using `HalvingGridSearchCV`\"\"\"\n",
    "    log(\"Tuning...\")\n",
    "    if len(param_grid) == 0:\n",
    "        param_grid = {\n",
    "            \"C\": [1, 10, 100, 1000],\n",
    "            \"gamma\": [\"scale\", \"auto\", 1, 0.01, 0.0001],\n",
    "        }\n",
    "    verbosity = 2 if VERBOSE else 0\n",
    "    sh = HalvingGridSearchCV(\n",
    "        base_estimator,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        factor=2,\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=verbosity,\n",
    "        random_state=RNG,\n",
    "    ).fit(X, y)\n",
    "    print(sh.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition 1 (layer 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L1\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L1], y_train[L.C1][Label.L1])\n",
    "    save_model(model, \"c1_label_1_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_1_before\")\n",
    "predict(model, X_valid[L.C1][Label.L1], y_valid[L.C1][Label.L1])\n",
    "y_pred_before[L.C1][Label.L1] = model.predict(X_test[L.C1][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L2\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L2], y_train[L.C1][Label.L2], C=1000)\n",
    "    save_model(model, \"c1_label_2_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_2_before\")\n",
    "predict(model, X_valid[L.C1][Label.L2], y_valid[L.C1][Label.L2])\n",
    "y_pred_before[L.C1][Label.L2] = model.predict(X_test[L.C1][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L3\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L3], y_train[L.C1][Label.L3])\n",
    "    save_model(model, \"c1_label_3_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_3_before\")\n",
    "predict(model, X_valid[L.C1][Label.L3], y_valid[L.C1][Label.L3])\n",
    "y_pred_before[L.C1][Label.L3] = model.predict(X_test[L.C1][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1, L4\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=RNG)\n",
    "    model.fit(X_train[L.C1][Label.L4], y_train[L.C1][Label.L4])\n",
    "    save_model(model, \"c1_label_4_before\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_4_before\")\n",
    "predict(model, X_valid[L.C1][Label.L4], y_valid[L.C1][Label.L4])\n",
    "y_pred_before[L.C1][Label.L4] = model.predict(X_test[L.C1][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Competition 2 (layer 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L1\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\")\n",
    "    model.fit(X_train[L.C2][Label.L1], y_train[L.C2][Label.L1])\n",
    "    save_model(model, \"c2_label_1_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_1_before\")\n",
    "predict(model, X_valid[L.C2][Label.L1], y_valid[L.C2][Label.L1])\n",
    "y_pred_before[L.C2][Label.L1] = model.predict(X_test[L.C2][Label.L1].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L2\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", C=1000)\n",
    "    model.fit(X_train[L.C2][Label.L2], y_train[L.C2][Label.L2])\n",
    "    save_model(model, \"c2_label_2_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_2_before\")\n",
    "predict(model, X_valid[L.C2][Label.L2], y_valid[L.C2][Label.L2])\n",
    "y_pred_before[L.C2][Label.L2] = model.predict(X_test[L.C2][Label.L2].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L3\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"linear\")\n",
    "    model.fit(X_train[L.C2][Label.L3], y_train[L.C2][Label.L3])\n",
    "    save_model(model, \"c2_label_3_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_3_before\")\n",
    "predict(model, X_valid[L.C2][Label.L3], y_valid[L.C2][Label.L3])\n",
    "y_pred_before[L.C2][Label.L3] = model.predict(X_test[L.C2][Label.L3].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C2, L4\n",
    "\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"linear\", class_weight=\"balanced\")\n",
    "    model.fit(X_train[L.C2][Label.L4], y_train[L.C2][Label.L4])\n",
    "    save_model(model, \"c2_label_4_before\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_4_before\")\n",
    "predict(model, X_valid[L.C2][Label.L4], y_valid[L.C2][Label.L4])\n",
    "y_pred_before[L.C2][Label.L4] = model.predict(X_test[L.C2][Label.L4].drop(ID, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "\n",
    "\n",
    "def fit_and_transform_pca(*X: pd.DataFrame):\n",
    "    pca = PCA(n_components=0.95, svd_solver=\"full\", random_state=RNG)\n",
    "    pca.fit(X[0])\n",
    "    X_trf = list(map(lambda x: pd.DataFrame(pca.transform(x)), X))\n",
    "    print(\"Shape after PCA:\", X_trf[0].shape)\n",
    "    return pca, *X_trf\n",
    "\n",
    "\n",
    "def univariate_feature_selection(X: pd.DataFrame, y: pd.Series, feature_count=30):\n",
    "    FROM_MODEL = False\n",
    "    if FROM_MODEL:\n",
    "        clf = ExtraTreesClassifier(n_estimators=50, random_state=RNG)\n",
    "        clf = clf.fit(X, y)\n",
    "        selector = SelectFromModel(clf, prefit=True)\n",
    "    else:\n",
    "        score_func = f_classif\n",
    "        selector = SelectKBest(score_func, k=feature_count)\n",
    "        selector = selector.fit(X, y)\n",
    "    X_new = selector.transform(X)\n",
    "    print(\"Shape after univariate:\", X_new.shape)\n",
    "    return selector, X_new\n",
    "\n",
    "\n",
    "def combine_transformers(*transformers):\n",
    "    def combined_transform(X):\n",
    "        for transformer in transformers:\n",
    "            X = transformer.transform(X)\n",
    "        return X\n",
    "\n",
    "    return combined_transform\n",
    "\n",
    "\n",
    "def transform(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    X_valid: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    pca_count=5,\n",
    "    feature_drop=0,\n",
    "):\n",
    "    if pca_count > 0:\n",
    "        log(\"Running PCA...\")\n",
    "        transformers = [None for _ in range(pca_count)]\n",
    "        transformers[0], X_train_trf, X_valid_trf, X_test_trf = fit_and_transform_pca(\n",
    "            X_train, X_valid, X_test\n",
    "        )\n",
    "    else:\n",
    "        log(\"Skipping PCA...\")\n",
    "        transformers = []\n",
    "        X_train_trf, X_valid_trf, X_test_trf = X_train, X_valid, X_test\n",
    "\n",
    "    # Skip univariate feature selection if `feature_drop` is specified as 0\n",
    "    if feature_drop != 0:\n",
    "        log(\"Running univariate feature selection...\")\n",
    "        current_feature_count = X_train_trf.shape[1]\n",
    "        selector, X_train_trf = univariate_feature_selection(\n",
    "            X_train_trf,\n",
    "            y_train,\n",
    "            feature_count=current_feature_count - feature_drop,\n",
    "        )\n",
    "        X_valid_trf = pd.DataFrame(selector.transform(X_valid_trf))\n",
    "        X_test_trf = pd.DataFrame(selector.transform(X_test_trf))\n",
    "        transformers.append(selector)\n",
    "\n",
    "    if pca_count > 1:\n",
    "        log(f\"Running PCA {pca_count - 1} times...\")\n",
    "        for i in range(pca_count - 1):\n",
    "            (\n",
    "                transformers[i + 1],\n",
    "                X_train_trf,\n",
    "                X_valid_trf,\n",
    "                X_test_trf,\n",
    "            ) = fit_and_transform_pca(X_train_trf, X_valid_trf, X_test_trf)\n",
    "\n",
    "    return X_train_trf, X_valid_trf, X_test_trf, combine_transformers(*transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 1 (layer 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C1][Label.L1],\n",
    "    y_train[L.C1][Label.L1],\n",
    "    X_valid[L.C1][Label.L1],\n",
    "    X_test[L.C1][Label.L1].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    param_grid = {\n",
    "        \"iterations\": [100, 200, 300],\n",
    "        \"loss_function\": [\"MultiClass\"],\n",
    "        \"max_depth\": range(4, 10, 2),\n",
    "    }\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=100, gamma=0.0001, random_state=RNG)\n",
    "    model = CatBoostClassifier(iterations=100, depth=6, random_state=RNG_SEED)\n",
    "    # tune(model, X_train_trf, y_train[L.C1][Label.L1], param_grid=param_grid)\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C1][Label.L1])\n",
    "    save_model(model, \"c1_label_1_after\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_1_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C1][Label.L1])\n",
    "y_pred_after[L.C1][Label.L1] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C1][Label.L2],\n",
    "    y_train[L.C1][Label.L2],\n",
    "    X_valid[L.C1][Label.L2],\n",
    "    X_test[L.C1][Label.L2].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", C=1000, gamma=0.0001, random_state=RNG, verbose=True)\n",
    "    # tune(model, X_train_trf, y_train[L.C1][Label.L3])\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C1][Label.L2])\n",
    "    # save_model(model, \"c1_label_2_after\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_2_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C1][Label.L2])\n",
    "y_pred_after[L.C1][Label.L2] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C1][Label.L3],\n",
    "    y_train[L.C1][Label.L3],\n",
    "    X_valid[L.C1][Label.L3],\n",
    "    X_test[L.C1][Label.L3].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=100, gamma='scale', random_state=RNG, verbose=True)\n",
    "    model = svm.SVC(kernel=\"rbf\", random_state=RNG, verbose=True)\n",
    "    # tune(model, X_train_trf, y_train[L.C1][Label.L3])\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C1][Label.L3])\n",
    "    save_model(model, \"c1_label_3_after\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_3_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C1][Label.L3])\n",
    "y_pred_after[L.C1][Label.L3] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C1][Label.L4],\n",
    "    y_train[L.C1][Label.L4],\n",
    "    X_valid[L.C1][Label.L4],\n",
    "    X_test[L.C1][Label.L4].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    model = svm.SVC(kernel=\"rbf\", class_weight=\"balanced\", random_state=RNG, verbose=True)\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C1][Label.L4])\n",
    "    save_model(model, \"c1_label_4_after\")\n",
    "else:\n",
    "    model = load_model(\"c1_label_4_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C1][Label.L4])\n",
    "y_pred_after[L.C1][Label.L4] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Competition 2 (layer 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C2][Label.L1],\n",
    "    y_train[L.C2][Label.L1],\n",
    "    X_valid[L.C2][Label.L1],\n",
    "    X_test[L.C2][Label.L1].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=1000, gamma=\"scale\", random_state=RNG)\n",
    "    model = CatBoostClassifier(random_state=RNG_SEED)\n",
    "    # param_grid = {\n",
    "    #     \"iterations\": [100, 200, 300],\n",
    "    #     \"depth\": [4, 6, 8],\n",
    "    # }\n",
    "    # tune(model, X_train_trf, y_train[L.C2][Label.L1], param_grid=param_grid)\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C2][Label.L1])\n",
    "    save_model(model, \"c2_label_1_after\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_1_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C2][Label.L1])\n",
    "y_pred_after[L.C2][Label.L1] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C2][Label.L2],\n",
    "    y_train[L.C2][Label.L2],\n",
    "    X_valid[L.C2][Label.L2],\n",
    "    X_test[L.C2][Label.L2].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "\n",
    "if RETRAIN:\n",
    "    model = CatBoostClassifier(random_state=RNG_SEED)\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=100, gamma='scale', random_state=RNG)\n",
    "    # tune(model, X_train_trf, y_train[L.C2][Label.L2])\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C2][Label.L2])\n",
    "    save_model(model, \"c2_label_2_after\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_2_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C2][Label.L2])\n",
    "y_pred_after[L.C2][Label.L2] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C2][Label.L3],\n",
    "    y_train[L.C2][Label.L3],\n",
    "    X_valid[L.C2][Label.L3],\n",
    "    X_test[L.C2][Label.L3].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    param_grid = {\n",
    "        \"iterations\": [100, 200, 300],\n",
    "        \"loss_function\": [\"MultiClass\"],\n",
    "        \"max_depth\": range(4, 10, 2),\n",
    "    }\n",
    "    model = CatBoostClassifier(iterations=300, loss_function=\"MultiClass\", max_depth=6, random_state=RNG_SEED)\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=10, random_state=RNG)\n",
    "    # tune(model, X_train_trf, y_train[L.C2][Label.L3], param_grid=param_grid)\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C2][Label.L3])\n",
    "    save_model(model, \"c2_label_3_after\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_3_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C2][Label.L3])\n",
    "y_pred_after[L.C2][Label.L3] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf, X_valid_trf, X_test_trf, selector = transform(\n",
    "    X_train[L.C2][Label.L4],\n",
    "    y_train[L.C2][Label.L4],\n",
    "    X_valid[L.C2][Label.L4],\n",
    "    X_test[L.C2][Label.L4].drop(ID, axis=1),\n",
    "    pca_count=1,\n",
    "    feature_drop=0,\n",
    ")\n",
    "if RETRAIN:\n",
    "    # model = svm.SVC(kernel=\"rbf\", C=100, class_weight=\"balanced\", verbose=True, random_state=RNG)\n",
    "    model = CatBoostClassifier(random_state=RNG_SEED)\n",
    "    # tune(model, X_train_trf, y_train[L.C2][Label.L4])\n",
    "    log(\"Training...\")\n",
    "    model.fit(X_train_trf, y_train[L.C2][Label.L4])\n",
    "    save_model(model, \"c2_label_4_after\")\n",
    "else:\n",
    "    model = load_model(\"c2_label_4_after\")\n",
    "predict(model, X_valid_trf, y_valid[L.C2][Label.L4])\n",
    "y_pred_after[L.C2][Label.L4] = model.predict(X_test_trf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_test[layer-7][label_1]:\", X_test[L.C1][Label.L1].shape)\n",
    "print(\"y_pred[layer-7][label_1]:\", y_pred_after[L.C1][Label.L1].shape)\n",
    "print(\"X_test[layer-12][label_1]:\", X_test[L.C2][Label.L1].shape)\n",
    "print(\"y_pred[layer-12][label_1]:\", y_pred_after[L.C2][Label.L1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame(columns=[ID] + LABELS)\n",
    "result1[ID] = X_test[L.C1][Label.L1][ID]\n",
    "for label in Label:\n",
    "    result1[label.value] = y_pred_after[L.C1][label].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = pd.DataFrame(columns=[ID] + LABELS)\n",
    "result2[ID] = X_test[L.C2][Label.L1][ID]\n",
    "for label in Label:\n",
    "    result2[label.value] = y_pred_after[L.C2][label].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1.to_csv(\"results/layer-7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(\"results/layer-12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
